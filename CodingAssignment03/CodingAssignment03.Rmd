---
title: "Coding Assignment 3"
author: "Team 8"
date: "Due: 2021-12-09 23:59"
output: 
  html_document:
    toc: true
    toc_float: true
    
---

```{r setup, include=FALSE}
#Put any packages you need here

knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(corrplot)
library(gt)
library(plotly)
library(car)

library(gt) # for better looking tables
library(gtsummary) # for better summary statistics
library(tidyverse)


```

A Florida health insurance company wants to predict annual claims for individual clients. The company pulls a random sample of 50 customers. The owner wishes to charge an actuarially fair premium to ensure a normal rate of return. The owner collects all of their current customer’s health care expenses from the last year and compares them with what is known about each customer’s plan. 

The data on the 50 customers in the sample is as follows:

-	Charges: Total medical expenses for a particular insurance plan (in dollars)
-	Age: Age of the primary beneficiary
-	BMI: Primary beneficiary’s body mass index (kg/m2)
-	Female: Primary beneficiary’s birth sex (0 = Male, 1 = Female)
-	Children: Number of children covered by health insurance plan (includes other dependents as well)
-	Smoker: Indicator if primary beneficiary is a smoker (0 = non-smoker, 1 = smoker)
-	Cities: Dummy variables for each city with the default being Sanford

Answer the following questions using complete sentences and attach all output, plots, etc. within this report.


```{r dataset, include=FALSE}
# (H1)  Bring in the dataset here.

insurance <- read.csv("../Data/insurance_0126_Group8.csv")

gt(head(insurance)) 

```



# Question 1

Randomly select three observations from the sample and exclude from all modeling (i.e. n=47). Provide the summary statistics (min, max, std, mean, median) of the quantitative variables for the 47 observations.

```{r q1}

set.seed(123456)
index <- sample(seq_len(nrow(insurance)), size = 3)

#data set of 47 observations ALL columns
insurance_train <- insurance[-index,]

#data set of 3 observations ALL columns
insurance_test <- insurance[index,]

#data set of 47 observations NO DUMMY columns (only 4 quantitative columns)
insurance_reduce <- insurance_train[,c(1:3,5)]

summary(insurance_reduce)

## [1] Standard deviation for Charges

sd(insurance_train$Charges)

## [1] Standard deviation for Age

sd(insurance_train$Age)

## [1] Standard deviation for BMI

sd(insurance_train$BMI)

## [1] Standard deviation for Children

sd(insurance_train$Children)

insurance_train %>% 
  tbl_summary(statistic = list(all_continuous() ~ c("{mean} ({sd})",
                                                    "{median} ({p25}, {p75})",
                                                    "{min}, {max}"),
                              all_categorical() ~ "{n} / {N} ({p}%)"),
              type = all_continuous() ~ "continuous2"
)

```
### Summary: 

There are 7 variables and 50 observations in the dataset. 47 observations of the variables in the dataset are potential predictor of the of the Insurance charges. From the data collected below are the properties of the statistical distribution. 

**Charges**: The minimum value of the selected 47 samples was 1640, where the max is 47404, their range was 45764. The mean and medium sample were 13310 and 8968. As mean was larger than the median, the model skewed right. The standard deviation of the sample was 11,706.

* Min. = 1640 ; Max. = 47404 ; Range = 45764
* Mean = 13310 ; Median = 8968 ; As mean > median, therefore, skewed right.
* Standard Deviation = 11,706

**Age**: The minimum value of the selected 47 samples was 19.00,
where the max was 63.00, their range was 44. The mean and
the median of the sample size were 40.98 and 41.00. As mean and median are close together, so it will be be symmetric but skewed slightly to the left. The standard deviation of the samples was 13.

* Min. = 19.00 ; Max. = 63.00 ; Range = 44
* Mean = 40.98; Median = 41.00 ; As mean and median are close together, so it will be be symmetric but skewed slightly to the left. 
* Standard deviation = 13

**BMI**: The minimum value of the selected 47 samples was 18.34, where the maximum was 49.06, their range was 30.72. The mean and
the median of the sample size were 32.81 and 31.64. Because the mean and median are close together, it will be be symmetric but skewed slightly to the right. The standard deviation of the samples was 6.2.

* Min. = 18.34 ; Max. = 49.06 ; Range = 30.72
* Mean = 32.81 ; Median = 31.64 ; As mean and median are close together, so it will be be symmetric but skewed slightly to the right. 
* Standard deviation = 6.2

**Children**: The minimum value of the selected 47 samples was 0, where the maximum was 5, their range was 5. The mean and the median of the sample size were 1.128 and 1.00. The mean and median are close together, so it will be be symmetric but skewed slightly to the right. The standard deviation of the samples was 4.3.

* Min. = 00.00 ; Max. = 5.00 ; Range = 5.00
* Mean = 1.128 ; Median = 1.00 ; As mean and median are close together, so it will be be symmetric but skewed slightly to the right. 
* Standard deviation = 4.3


# Question 2

Provide the correlation between all quantitative variables

```{r q2}

corrplot(cor(insurance_train[,c(1:3,5)]),
type = "lower",
order = "hclust",
tl.col = "black",
tl.srt = 45,
addCoef.col = "black",
diag = FALSE)

```

### Summary:
Based off the correlation matrix and the seven variables found in the data set above you can see that the variables have high weak correlation with one another. Of all 7 variables we found the weakest correlation between “charges”, “age”, “children”, and “BMI”. 


# Question 3

Run a regression that includes all independent variables in the data table. Does the model above violate any of the Gauss-Markov assumptions? If so, what are they and what is the solution for correcting?

```{r q3}
bad_model <- lm(Charges ~., data = insurance_train)

summary(bad_model)

par(mfrow=c(2,2))
plot(bad_model)

```

### Summary:
The **Gauss Markov Assumptions** guarantee the validity of ordinary least squares for estimating regression coefficients. Within our examples of plots we found the following violations: 

 1. The first plot titled “Residuals vs. Fitted,” you do not see a true pattern and it shows that it has a non-linear relationship. This violates a classical assumption.

 2. The second plot titled “Normal Q-Q” shows violates the assumption of a normally distributed dependent variable for a fixed set of predictors. 

 3. The third plot titled “Scale-Location” violates Heteroscedasticity. If this assumption were not violated, you’d see random points around a horizontal line. In this case, it is upwards sloping then goes down on the right hand side, so you can see there is a “fanning out” effect.

 4. The last plot “Residuals vs. Leverage” violates regression outliers, influential observations, and high leverage points.

# Question 4

Implement the solutions from question 3, such as data transformation, along with any other changes you wish. Use the sample data and run a new regression. How have the fit measures changed? How have the signs and significance of the coefficients changed?



```{r q4_1}

## Scatterplot for quantitative variable

scatterplotMatrix(insurance_reduce)


## plotting all histogram and transformation 


# Lncharges -- Logrithmic 

par(mfrow=c(1,2))

hist(insurance_train$Charges, main="Charges") #before

insurance_train$LnCharges <- log(insurance_train$Charges)

hist(insurance_train$LnCharge,main="LnCharges") #after

## charges -- qudratic 

par(mfrow=c(1,2))

hist(insurance_train$Charges, main="Charges") #before

insurance_train$Chargessquared <- log(insurance_train$Charges^2)

hist(insurance_train$Chargessquared, main="Chargesquared") #after

## Age - Logrithmic 

par(mfrow=c(1,2))

hist(insurance_train$Age, main="Age") #before

insurance_train$LnAge <- log(insurance_train$Age)

hist(insurance_train$LnAge, main="LnAge") #after


## Age - quadratic 

par(mfrow=c(1,2))

hist(insurance_train$Age, main="Age") #before

insurance_train$Agesquared <- log(insurance_train$Age^2)

hist(insurance_train$Agesquared, main="Agesquared") #after

## BMI - Logrithmic

par(mfrow=c(1,2))

hist(insurance_train$BMI, main="BMI") #before

insurance_train$LnBMI <- log(insurance_train$BMI)

hist(insurance_train$LnBMI, main="LnBMI") #after

## BMI - quadratic

par(mfrow=c(1,2))

hist(insurance_train$BMI, main="BMI") #before

insurance_train$BMIsquared <- log(insurance_train$BMI^2)

hist(insurance_train$BMIsquared, main="BMIsquared") #after

##Only Male charges -- we tried to seperate male in to category 

insurance_train$Maleonly <- insurance_train$Female =="0"

##Only Female charges - we tried to seperate female in to category

insurance_train$Femaleonly <- insurance_train$Female =="1"

##Only nonsmoker - We tried to seperate non smoker in to category

insurance_train$nonsmokeronly <- insurance_train$Smoker =="0"

##Only smoker - We tried to seperate smoker in to category

insurance_train$smokeronly <- insurance_train$Smoker =="1"

#Testing Different Models 


## Testing model with LnCharges with all variable same


model_1 <- lm(LnCharges  ~ Age +  BMI + Female + Children +Smoker + WinterSprings + WinterPark + Oviedo , data = insurance_train) #pulling only columns I want

summary(model_1)


# or

tbl_regression(model_1,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_1)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_1)

##testing model with LnCharges , LnAge , LnBMI ,Children +Smoker

model_2 <- lm(LnCharges  ~ LnAge + LnBMI + Female + Children +Smoker , data = insurance_train) #pulling only columns I want
summary(model_2)

# or

tbl_regression(model_2,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_2)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_2)

##testing model with LnCharges and BMI squared

model_3 <- lm(LnCharges  ~ LnAge + BMIsquared + BMI + Female + Children +Smoker , data = insurance_train) #pulling only columns I want
summary(model_3)

# or

tbl_regression(model_3,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_3)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_3)

## ##testing model with LnCharges and AGE squared and LnBMI

model_4 <- lm(LnCharges  ~ Agesquared + Age + LnBMI + Female + Children +Smoker , data = insurance_train) #pulling only columns I want
summary(model_4)

# or

tbl_regression(model_4,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_4)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_4)

## Testing using LnCharges LnAge and LnBMI with only Female and Smoker

model_5 <- lm(LnCharges  ~ LnAge + LnBMI + Female +Smoker  , data = insurance_train) #pulling only columns I want
summary(model_5)

# or

tbl_regression(model_5,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_5)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_5)


## Testing LnCharges to only Maleonly + smoker 

model_6 <- lm(LnCharges  ~ LnAge +  LnBMI  + smokeronly + Maleonly  , data = insurance_train) #pulling only columns I want
summary(model_6)

# or

tbl_regression(model_6,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_6)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_6)

## Testing LnCharges to only maleonly smoker + children

model_7 <- lm(LnCharges  ~ LnAge +  LnBMI  + smokeronly + Maleonly + Children   , data = insurance_train) #pulling only columns I want
summary(model_7)

# or

tbl_regression(model_7,
               estimate_fun =  ~style_sigfig(.x, digits = 4)) %>% as_gt() %>%
  gt::tab_source_note(gt::md(paste0("Adjusted R-Squared: ",round(summary(model_7)$adj.r.squared* 100,digits = 2),"%")))

par(mfrow=c(2,2))
plot(model_7)

```

### Summary: 

Looking at the scatter plot and histograms, we only included quantitative variables, and excluded all others. The scatter plot matrix showed some non-linear relationships and non-normally distributed variables.  

Using data transformation, the natural logarithm of charges results in something closer to a normal distribution. However, the natural logarithm of age, and BMI does not result in a normal distribution. Below is a summary of our findings within 7 models:

**Model 1**: By taking the log of Charges, Age, BMI, Female, Children, Smoker, Winter Springs, Winter Park, and Oviedo it brought the outliers closer to Charges. Here we can see that Age, Female, and Smoker test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4368. 

**Model 2**: By taking the log of Charges, Age, BMI, Female, Children, and Smoker we can see that Age, BMI, Female, and Smoker test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4245.

**Model 3**: By taking the log of Charges, Age, BMI squared, Female, Children, and Smoker we can see that Age, Female, and Smoker test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4296.

**Model 4**: By taking the log of Charges, Age squared, Age, BMI, Female, Children, and Smoker we can see that BMI, Female, and Smoker test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4289.

**Model 5**: By taking the log of Charges, log of Age, log of BMI, Female, and Smoker we can see that all variables test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4231.

**Model 6**: By taking the log of Charges, log of Age, log of BMI, Smoker Only and Male Only we can see that all variables test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4231.

**Model 7**: By taking the log of Charges, log of Age, log of BMI, Smoker Only, Male Only, and Children we can see that all variables, except Children, test significant and have multiple R2 of 78%. Additionally, the residual standard error is 0.4245.


# Question 5

Use the 3 withheld observations and calculate the performance measures for your best two models. Which is the better model? (remember that "better" depends on whether your outlook is short or long run)

```{r q5}

insurance_test$LnCharges <- log(insurance_test$Charges)

insurance_test$Chargessquared <- log(insurance_test$Charges^2)

insurance_test$LnAge <- log(insurance_test$Age)

insurance_test$Agesquared <- log(insurance_test$Age^2)

insurance_test$LnBMI <- log(insurance_test$BMI)


insurance_test$BMIsquared <- log(insurance_test$BMI^2)

insurance_test$Maleonly <- insurance_test$Female =="0"

insurance_test$Femaleonly <- insurance_test$Female =="1"

insurance_test$nonsmokeronly <- insurance_test$Smoker =="0"

insurance_test$smokeronly <- insurance_test$Smoker =="1"



insurance_test$bad_model_pred <- predict(bad_model, newdata = insurance_test)
insurance_test$model_1_pred <- predict(model_1,newdata = insurance_test) %>% exp()
insurance_test$model_2_pred <- predict(model_2,newdata = insurance_test) %>% exp()

insurance_test$model_3_pred <- predict(model_3,newdata = insurance_test) %>% exp()
insurance_test$model_4_pred <- predict(model_4,newdata = insurance_test) %>% exp()

insurance_test$model_5_pred <- predict(model_5,newdata = insurance_test) %>% exp()
insurance_test$model_6_pred <- predict(model_6,newdata = insurance_test) %>% exp()

insurance_test$model_7_pred <- predict(model_7,newdata = insurance_test) %>% exp()

# Finding the error
insurance_test$error_bm <- insurance_test$bad_model_pred - insurance_test$Charges
insurance_test$error_1 <- insurance_test$model_1_pred - insurance_test$Charges
insurance_test$error_2 <- insurance_test$model_2_pred - insurance_test$Charges
insurance_test$error_3 <- insurance_test$model_3_pred - insurance_test$Charges
insurance_test$error_4 <- insurance_test$model_4_pred - insurance_test$Charges
insurance_test$error_5 <- insurance_test$model_5_pred - insurance_test$Charges
insurance_test$error_6 <- insurance_test$model_6_pred - insurance_test$Charges
insurance_test$error_7 <- insurance_test$model_7_pred - insurance_test$Charges

#Bias
# Bad Model
mean(insurance_test$error_bm)

# Model 1
mean(insurance_test$error_1)

# Model 2
mean(insurance_test$error_2)

# Model 3
mean(insurance_test$error_3)

# Model 4
mean(insurance_test$error_4)

# Model 5
mean(insurance_test$error_5)

# Model 6
mean(insurance_test$error_6)

# Model 7
mean(insurance_test$error_7)


#MAE
#  function to calculate this
mae <- function(error_vector){
error_vector %>%
abs() %>%
mean()
}
# Bad Model
mae(insurance_test$error_bm)

# Model 1
mae(insurance_test$error_1)

# Model 2
mae(insurance_test$error_2)

# Model 3
mae(insurance_test$error_3)

# Model 4
mae(insurance_test$error_4)

# Model 5
mae(insurance_test$error_5)

# Model 6
mae(insurance_test$error_6)

# Model 7
mae(insurance_test$error_7)


##RMSE
rmse <- function(error_vector){
   error_vector^2 %>% 
  mean() %>% 
  sqrt()

}

# Bad Model
rmse(insurance_test$error_bm)

# Model 1
rmse(insurance_test$error_1)


# Model 2
rmse(insurance_test$error_2)

# Model 3
rmse(insurance_test$error_3)

# Model 4
rmse(insurance_test$error_4)

# Model 5
rmse(insurance_test$error_5)

# Model 6
rmse(insurance_test$error_6)

# Model 7
rmse(insurance_test$error_7)



### MAPE


mape <- function(error_vector, actual_vector){
  (error_vector/actual_vector) %>% 
    abs() %>% 
    mean()
}

# Bad Model
mape(insurance_test$error_bm, insurance_test$Charges)

# Model 1
mape(insurance_test$error_1, insurance_test$Charges)

# Model 2
mape(insurance_test$error_2, insurance_test$Charges)

# Model 3
mape(insurance_test$error_3, insurance_test$Charges)

# Model 4
mape(insurance_test$error_4, insurance_test$Charges)

# Model 5
mape(insurance_test$error_5, insurance_test$Charges)

# Model 6
mape(insurance_test$error_6, insurance_test$Charges)

# Model 7
mape(insurance_test$error_7, insurance_test$Charges)

```
### Summary: 

Looking at the 7 Models, 5 and 7 are our best models. Model 7 is a good fit for a short-run, while Model 5 is a best fit for a long-run. Based on our time preference, we picked Model 5 as the best model because it tests significant and has lower BIAS, MAE, RMSE, and MAPE.  

# Question 6

Provide interpretations of the coefficients, do the signs make sense? Perform marginal change analysis (thing 2) on the independent variables.

```{r}

## BEST MODEL MODEL 5
## Testing using LnAge and LnBMI with only Female and Smoker

model_5 <- lm(Charges  ~ LnAge + LnBMI + Female +Smoker  , data = insurance_train) #pulling only columns I want
summary(model_5)

## BEST MODEL MODEL 7
## Testing LnCharges to only maleonly smoker + children

model_7 <- lm(LnCharges  ~ LnAge +  LnBMI  + smokeronly + Maleonly + Children   , data = insurance_train) #pulling only columns I want
summary(model_7)

```

### Summary:
After reviewing the coefficients, the coefficient signs for Age, BMI, smoker, female and/or male tested significant and have a direct relationship with the dependent variable (Charges).

And if you think about it logically, getting pregnant and/or having a child will increase medical charges and premiums. Smoking will also have a direct and positive coefficient because being a smoker will only increase medical costs. For Age and BMI each year, it will increase. Because if you change x by one, we’d expect y to change by β1.


# Question 7

An eager insurance representative comes back with five potential clients. Using the better of the two models selected above, provide the prediction intervals for the five potential clients using the information provided by the insurance rep.

| Customer | Age | BMI | Female | Children | Smoker | City           |
| -------- | --- | --- | ------ | -------- | ------ | -------------- | 
| 1        | 60  | 22  | 1      | 0        | 0      | Oviedo         |
| 2        | 40  | 30  | 0      | 1        | 0      | Sanford        |
| 3        | 25  | 25  | 0      | 0        | 1      | Winter Park    |
| 4        | 33  | 35  | 1      | 2        | 0      | Winter Springs |
| 5        | 45  | 27  | 1      | 3        | 0      | Oviedo         |


```{r}

Client_1 <- data.frame(LnAge = log(60) , LnBMI = log(22) , Age = 60, BMI = 22, Children = 0, Female = 1, Smoker = 0, WinterSprings = 0, WinterPark = 0, Oviedo = 1)
Client_2 <- data.frame(LnAge = log(40),LnBMI = log(30), Age = 40, BMI = 30, Children = 1, Female = 0, Smoker = 0, WinterSprings = 0, WinterPark = 0, Oviedo = 0)
Client_3 <- data.frame(LnAge = log(25),LnBMI = log(25), Age = 25, BMI = 25, Children = 0, Female = 0, Smoker = 1, WinterSprings = 0, WinterPark = 1, Oviedo = 0)
Client_4 <- data.frame(LnAge = log(33),LnBMI = log(35), Age = 33, BMI = 35, Children = 2, Female = 1, Smoker = 0, WinterSprings = 1, WinterPark = 0, Oviedo = 1)
Client_5 <- data.frame(LnAge = log(45),LnBMI = log(27), Age = 45, BMI = 27, Children = 3, Female = 1, Smoker = 0, WinterSprings = 0, WinterPark = 0, Oviedo = 1)

### Prediction based on model_5

## model_5 <- lm(LnCharges  ~ LnAge + LnBMI + Female +Smoker  , data = insurance_train)

predict(model_5, newdata= Client_1, interval = "prediction")

predict(model_5, newdata= Client_2, interval = "prediction")

predict(model_5, newdata= Client_3, interval = "prediction")

predict(model_5, newdata= Client_4, interval = "prediction")

predict(model_5, newdata= Client_5, interval = "prediction")


### Prediction based on model_7
## model_7 <- lm(LnCharges  ~ LnAge +  LnBMI  + smokeronly + Maleonly + Children   , data = insurance_train)

Client_1 <- data.frame(LnAge = log(60) , LnBMI = log(22) , Age = 60, BMI = 22, Children = 0, Maleonly = FALSE, smokeronly = FALSE, WinterSprings = 0, WinterPark = 0, Oviedo = 1)
Client_2 <- data.frame(LnAge = log(40),LnBMI = log(30), Age = 40, BMI = 30, Children = 1, Maleonly = TRUE, smokeronly = FALSE, WinterSprings = 0, WinterPark = 0, Oviedo = 0)
Client_3 <- data.frame(LnAge = log(25),LnBMI = log(25), Age = 25, BMI = 25, Children = 0, Maleonly = TRUE, smokeronly = TRUE, WinterSprings = 0, WinterPark = 1, Oviedo = 0)
Client_4 <- data.frame(LnAge = log(33),LnBMI = log(35), Age = 33, BMI = 35, Children = 2, Maleonly = FALSE, smokeronly = FALSE, WinterSprings = 1, WinterPark = 0, Oviedo = 1)
Client_5 <- data.frame(LnAge = log(45),LnBMI = log(27), Age = 45, BMI = 27, Children = 3, Maleonly = FALSE, smokeronly = FALSE, WinterSprings = 0, WinterPark = 0, Oviedo = 1)

predict(model_7, newdata= Client_1, interval = "prediction")

predict(model_7, newdata= Client_2, interval = "prediction")

predict(model_7, newdata= Client_3, interval = "prediction")

predict(model_7, newdata= Client_4, interval = "prediction")

predict(model_7, newdata= Client_5, interval = "prediction")


```
### Summary: 
The result indicates that for Client 1 the insurance representative can expect the value in medical expenses to be about 11,595.40 and that they can be 95 percent confident that the true value lies somewhere between 0 and 24,003.01.

The result indicates that for Client 2 the insurance representative can expect the value in medical expenses to be about 7,732.39 and that they can be 95 percent confident that the true value lies somewhere between 0 and 19,443.31.

The result indicates that for Client 3 the insurance representative can expect the value in medical expenses to be about 27,422.90 and that they can be 95 percent confident that the true value lies somewhere between 14,878.69 and 39,967.11.

The result indicates that for Client 4 the insurance representative can expect the value in medical expenses to be about 10,004.17 and that they can be 95 percent confident that the true value lies somewhere between 0 and 21,812.03.

The result indicates that for Client 5 the insurance representative can expect the value in medical expenses to be about 10,618.05 and that they can be 95 percent confident that the true value lies somewhere between 0 and 22,471.03.


# Question 8

The owner notices that some of the predictions are wider than others, explain why.

### Summary: 
The prediction interval predicts in what range a future individual observation will fall. Predictions for Clients 1 and 3 seem to be wider than the others.  For Client 1, their age (60) is likely the reason why the prediction is wider. For Client 3, the reason is likely due to them being a Smoker. Both factors may lead to more medical expenses. 

# Question 9 

Are there any prediction problems that occur with the five potential clients? If so, explain.

### Summary: 

The minimums for Clients 1,2, 4, and 5 are negative. This is likely due to the low number of observations, which can cause the model to have errors. 
